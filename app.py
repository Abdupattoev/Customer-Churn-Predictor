# -*- coding: utf-8 -*-
"""Copy of Welcome To Colab

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1f-_fB0zpBZLZ_qgiYSpCkXHRjH_wXbGk

# New Section
"""

import pandas as pd

# Load the dataset from a public URL
url = "https://raw.githubusercontent.com/IBM/telco-customer-churn-on-icp4d/master/data/Telco-Customer-Churn.csv"
df = pd.read_csv(url)

# Display the first 5 rows
print("--- Dataset Preview ---")
print(df.head())

# Look at the data types and missing values
print("\n--- Data Info ---")
print(df.info())                          # 1. Convert TotalCharges to numeric, turning spaces into 'NaN' (Not a Number)
df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')

# 2. Find out how many rows are now missing data
missing_values = df['TotalCharges'].isnull().sum()
print(f"Number of missing values in TotalCharges: {missing_values}")

# 3. Fill those missing values with 0 (since they are new customers)
df['TotalCharges'] = df['TotalCharges'].fillna(0)

# 4. Remove 'customerID' - it's just a random string and won't help predict churn
df.drop('customerID', axis=1, inplace=True)

print("Data cleaning complete!")
import seaborn as sns
import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(10, 6))
sns.histplot(data=df, x='tenure', hue='Churn', multiple='stack', palette='magma')
plt.title('Customer Retention by Tenure (Months)')
plt.xlabel('Months with Company')
plt.ylabel('Number of Customers')
plt.show()



plt.figure(figsize=(10, 6))
sns.kdeplot(df.loc[(df['Churn'] == 'No'), 'MonthlyCharges'], label='Stayed', shade=True)
sns.kdeplot(df.loc[(df['Churn'] == 'Yes'), 'MonthlyCharges'], label='Left', shade=True)
plt.title('Monthly Charges Distribution: Stayed vs Left')
plt.legend()
plt.show()

plt.figure(figsize=(8, 5))
sns.countplot(data=df, x='Contract', hue='Churn', palette='viridis')
plt.title('Churn Count by Contract Type')
plt.show()

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder

# 1. Create a copy to keep your original data safe
df_model = df.copy()

# 2. Encode all text columns to numbers (Label Encoding)
le = LabelEncoder()
for col in df_model.select_dtypes(include=['object']).columns:
    df_model[col] = le.fit_transform(df_model[col].astype(str))

# 3. Define Features (X) and Target (y)
X = df_model.drop('Churn', axis=1)
y = df_model['Churn']

# 4. Split the data (80% for learning, 20% for testing)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print("Success! Data is encoded and X_train is now defined.")

# Convert Churn to binary
df['Churn'] = df['Churn'].apply(lambda x: 1 if x == 'Yes' else 0)

import numpy as np
import IPython.display as display
from matplotlib import pyplot as plt
import io
import base64

ys = 200 + np.random.randn(100)
x = [x for x in range(len(ys))]

fig = plt.figure(figsize=(4, 3), facecolor='w')
plt.plot(x, ys, '-')
plt.fill_between(x, ys, 195, where=(ys > 195), facecolor='g', alpha=0.6)
plt.title("Sample Visualization", fontsize=10)

data = io.BytesIO()
plt.savefig(data)
image = F"data:image/png;base64,{base64.b64encode(data.getvalue()).decode()}"
alt = "Sample Visualization"
display.display(display.Markdown(F"""![{alt}]({image})"""))
plt.close(fig)

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder

# 1. Clean up categorical text into numbers so the model can read them
# We'll use a simple loop for now to get you moving
df_encoded = df.copy()
le = LabelEncoder()
for col in df_encoded.select_dtypes(include=['object']).columns:
    df_encoded[col] = le.fit_transform(df_encoded[col])

# 2. Define X and y
X = df_encoded.drop('Churn', axis=1)
y = df_encoded['Churn']

# 3. Create the training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print("X_train and y_train are now defined and ready!")

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder

# 1. Create a copy to keep your original data safe
df_model = df.copy()

# 2. Encode all text columns to numbers (Label Encoding)
le = LabelEncoder()
for col in df_model.select_dtypes(include=['object']).columns:
    df_model[col] = le.fit_transform(df_model[col])

# 3. Define Features (X) and Target (y)
X = df_model.drop('Churn', axis=1)
y = df_model['Churn']

# 4. Split the data (80% for learning, 20% for testing)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print("Success! Data is encoded and X_train is now defined.")

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix

# 1. Initialize the model
# We use class_weight='balanced' because fewer people churn than stay
rf_model = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')

# 2. Train the model
rf_model.fit(X_train, y_train)

# 3. Make predictions on the test set
y_pred = rf_model.predict(X_test)

# 4. Check the results
print("--- Confusion Matrix ---")
print(confusion_matrix(y_test, y_pred))
print("\n--- Classification Report ---")
print(classification_report(y_test, y_pred))

import pandas as pd
import matplotlib.pyplot as plt

# Get feature importances
importances = rf_model.feature_importances_
feature_names = X.columns
feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})
feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False).head(10)

# Plot
plt.figure(figsize=(10, 6))
sns.barplot(x='Importance', y='Feature', data=feature_importance_df, palette='magma')
plt.title('Top 10 Drivers of Customer Churn')
plt.show()

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

# 1. Initialize with 'balanced' weights
rf_model = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42, class_weight='balanced')

# 2. Train using the X_train we defined in the 'Encoding Bridge'
rf_model.fit(X_train, y_train)

# 3. Predict
y_pred = rf_model.predict(X_test)

# 4. Display the 'Resume-Ready' stats
print(f"Overall Accuracy: {accuracy_score(y_test, y_pred):.2f}")
print("\n--- Detailed Performance Report ---")
print(classification_report(y_test, y_pred))

def predict_churn(customer_data):
    # This takes a list of data in the same order as X_train
    prediction = rf_model.predict([customer_data])
    probability = rf_model.predict_proba([customer_data])[0][1]

    result = "CHURN RISK" if prediction[0] == 1 else "LOYAL"
    print(f"Analysis Result: {result}")
    print(f"Churn Probability: {probability*100:.2f}%")

# Example: A new customer with 1 month tenure and high charges
# Note: You'd need to provide all features encoded exactly as X_test
example_customer = X_test.iloc[0].values
predict_churn(example_customer)

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix

# Load Data
url = "https://raw.githubusercontent.com/IBM/telco-customer-churn-on-icp4d/master/data/Telco-Customer-Churn.csv"
df = pd.read_csv(url)

# Clean Data
df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce').fillna(0)
df.drop('customerID', axis=1, inplace=True)
df['Churn'] = df['Churn'].apply(lambda x: 1 if x == 'Yes' else 0)

print("Step 1 Complete: Data is clean and target is encoded.")

# Encode categorical text into numbers
df_model = df.copy()
le = LabelEncoder()
for col in df_model.select_dtypes(include=['object']).columns:
    df_model[col] = le.fit_transform(df_model[col].astype(str))

# Split into Training and Testing sets
X = df_model.drop('Churn', axis=1)
y = df_model['Churn']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print("Step 2 Complete: X_train and y_train are now defined.")

# Train Model
rf_model = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')
rf_model.fit(X_train, y_train)

# Check results
y_pred = rf_model.predict(X_test)
print("--- Classification Report ---")
print(classification_report(y_test, y_pred))

importances = rf_model.feature_importances_
feature_importance_df = pd.DataFrame({'Feature': X.columns, 'Importance': importances})
feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False).head(10)

plt.figure(figsize=(10, 6))
sns.barplot(x='Importance', y='Feature', data=feature_importance_df, hue='Feature', palette='magma', legend=False)
plt.title('Top 10 Drivers of Customer Churn')
plt.show()

import joblib

# This saves the 'rf_model' you trained into a file called 'model.pkl'
joblib.dump(rf_model, 'model.pkl')

# If you used a LabelEncoder, save that too
# joblib.dump(le, 'encoder.pkl')

import joblib

# This only works if 'rf_model' was just trained in the cell above
try:
    joblib.dump(rf_model, 'model.pkl')
    print("Success! 'model.pkl' has been saved. Download it from the folder icon on the left.")
except NameError:
    print("Error: You need to run the cell where you defined 'rf_model' first!")